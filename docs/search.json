[
  {
    "objectID": "installation.html",
    "href": "installation.html",
    "title": "Installation",
    "section": "",
    "text": "pymetadata is available from pypi and can be installed via\npip install pymetadata\n\n\npymetadata caches some information for faster retrieval. The cache path is set to\nCACHE_PATH: Path = Path.home() / \".cache\" / \"pymetadata\"\nTo use a custom cache path use\nimport pymetadata\npymetadata.CACHE_PATH = &lt;cache_path&gt;",
    "crumbs": [
      "Installation"
    ]
  },
  {
    "objectID": "installation.html#cache-path",
    "href": "installation.html#cache-path",
    "title": "Installation",
    "section": "",
    "text": "pymetadata caches some information for faster retrieval. The cache path is set to\nCACHE_PATH: Path = Path.home() / \".cache\" / \"pymetadata\"\nTo use a custom cache path use\nimport pymetadata\npymetadata.CACHE_PATH = &lt;cache_path&gt;",
    "crumbs": [
      "Installation"
    ]
  },
  {
    "objectID": "development.html",
    "href": "development.html",
    "title": "Development",
    "section": "",
    "text": "To set up everything for the develop environment use\n# install core dependencies\nuv sync\n\n# install dev dependencies\nuv pip install -r pyproject.toml --extra dev\nuv tool install tox --with tox-uv\n\n# setup pre-commit hook\nuv pip install pre-commit\npre-commit install\npre-commit run\n\n\n\nTesting is performed with pytest and tox:\nRun single tox target:\ntox r -e py314\nRun all tests in parallel:\ntox run-parallel",
    "crumbs": [
      "Contributing",
      "Development"
    ]
  },
  {
    "objectID": "development.html#setup-development-environment",
    "href": "development.html#setup-development-environment",
    "title": "Development",
    "section": "",
    "text": "To set up everything for the develop environment use\n# install core dependencies\nuv sync\n\n# install dev dependencies\nuv pip install -r pyproject.toml --extra dev\nuv tool install tox --with tox-uv\n\n# setup pre-commit hook\nuv pip install pre-commit\npre-commit install\npre-commit run",
    "crumbs": [
      "Contributing",
      "Development"
    ]
  },
  {
    "objectID": "development.html#testing",
    "href": "development.html#testing",
    "title": "Development",
    "section": "",
    "text": "Testing is performed with pytest and tox:\nRun single tox target:\ntox r -e py314\nRun all tests in parallel:\ntox run-parallel",
    "crumbs": [
      "Contributing",
      "Development"
    ]
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "Function reference",
    "section": "",
    "text": "Functionality related to COMBINE archive (OMEX).\n\n\n\nomex\nCOMBINE Archive support.\n\n\n\n\n\n\nFunctionality related to metadata and annotations.\n\n\n\ncore.annotation\nAnnotation.",
    "crumbs": [
      "API Reference",
      "Overview"
    ]
  },
  {
    "objectID": "api/index.html#combine-archive",
    "href": "api/index.html#combine-archive",
    "title": "Function reference",
    "section": "",
    "text": "Functionality related to COMBINE archive (OMEX).\n\n\n\nomex\nCOMBINE Archive support.",
    "crumbs": [
      "API Reference",
      "Overview"
    ]
  },
  {
    "objectID": "api/index.html#metadata",
    "href": "api/index.html#metadata",
    "title": "Function reference",
    "section": "",
    "text": "Functionality related to metadata and annotations.\n\n\n\ncore.annotation\nAnnotation.",
    "crumbs": [
      "API Reference",
      "Overview"
    ]
  },
  {
    "objectID": "api/core.annotation.html",
    "href": "api/core.annotation.html",
    "title": "core.annotation",
    "section": "",
    "text": "core.annotation\nAnnotation.\nCore data structure to store annotations.\n\n\n\n\n\nName\nDescription\n\n\n\n\nProviderType\nProvider type.\n\n\nRDFAnnotation\nRDFAnnotation class.\n\n\nRDFAnnotationData\nAnnotation with resolved information.\n\n\n\n\n\ncore.annotation.ProviderType()\nProvider type.\n\n\n\ncore.annotation.RDFAnnotation(qualifier, resource, validate=True)\nRDFAnnotation class.\nBasic storage of annotation information. This consists of the relation and the resource. The annotations can be attached to other objects thereby forming triples which can be converted to RDF.\n\n\n\nhttp(s)://identifiers.org/collection/term, i.e., a identifiers.org URI\ncollection/term, i.e., the combination of collection and term\nhttp(s)://arbitrary.url, an arbitrary URL\nurn:miriam:uniprot:P03023\nhttps://bioregistry.io/chebi:15996 urls via the bioregistry provider\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nresource_normalized\nNormalize resource for given annotation.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncheck_miriam_term\nCheck that term follows id pattern for collection.\n\n\ncheck_qualifier\nCheck that the qualifier is an allowed qualifier.\n\n\nfrom_tuple\nConstruct from tuple.\n\n\nshorten_compact_term\nShorten the compact terms and return term.\n\n\nto_dict\nConvert to dict.\n\n\nvalidate\nValidate annotation.\n\n\n\n\n\ncore.annotation.RDFAnnotation.check_miriam_term()\nCheck that term follows id pattern for collection.\nUses the Identifiers collection information.\n\n\n\ncore.annotation.RDFAnnotation.check_qualifier(qualifier)\nCheck that the qualifier is an allowed qualifier.\n:param qualifier: :return:\n\n\n\ncore.annotation.RDFAnnotation.from_tuple(t)\nConstruct from tuple.\n\n\n\ncore.annotation.RDFAnnotation.shorten_compact_term(term, collection)\nShorten the compact terms and return term.\nIf the namespace is not embedded in the term return the shortened term.\n\n\n\ncore.annotation.RDFAnnotation.to_dict()\nConvert to dict.\n\n\n\ncore.annotation.RDFAnnotation.validate()\nValidate annotation.\n\n\n\n\n\ncore.annotation.RDFAnnotationData(annotation)\nAnnotation with resolved information.\nqueries for the resource should happen here; this resolves additional information.\n\n\n\n\n\nName\nDescription\n\n\n\n\nquery_ols\nQuery ontology lookup service.\n\n\nto_dict\nConvert to dict.\n\n\n\n\n\ncore.annotation.RDFAnnotationData.query_ols()\nQuery ontology lookup service.\n\n\n\ncore.annotation.RDFAnnotationData.to_dict()\nConvert to dict.",
    "crumbs": [
      "API Reference",
      "Annotations"
    ]
  },
  {
    "objectID": "api/core.annotation.html#classes",
    "href": "api/core.annotation.html#classes",
    "title": "core.annotation",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nProviderType\nProvider type.\n\n\nRDFAnnotation\nRDFAnnotation class.\n\n\nRDFAnnotationData\nAnnotation with resolved information.\n\n\n\n\n\ncore.annotation.ProviderType()\nProvider type.\n\n\n\ncore.annotation.RDFAnnotation(qualifier, resource, validate=True)\nRDFAnnotation class.\nBasic storage of annotation information. This consists of the relation and the resource. The annotations can be attached to other objects thereby forming triples which can be converted to RDF.\n\n\n\nhttp(s)://identifiers.org/collection/term, i.e., a identifiers.org URI\ncollection/term, i.e., the combination of collection and term\nhttp(s)://arbitrary.url, an arbitrary URL\nurn:miriam:uniprot:P03023\nhttps://bioregistry.io/chebi:15996 urls via the bioregistry provider\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nresource_normalized\nNormalize resource for given annotation.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncheck_miriam_term\nCheck that term follows id pattern for collection.\n\n\ncheck_qualifier\nCheck that the qualifier is an allowed qualifier.\n\n\nfrom_tuple\nConstruct from tuple.\n\n\nshorten_compact_term\nShorten the compact terms and return term.\n\n\nto_dict\nConvert to dict.\n\n\nvalidate\nValidate annotation.\n\n\n\n\n\ncore.annotation.RDFAnnotation.check_miriam_term()\nCheck that term follows id pattern for collection.\nUses the Identifiers collection information.\n\n\n\ncore.annotation.RDFAnnotation.check_qualifier(qualifier)\nCheck that the qualifier is an allowed qualifier.\n:param qualifier: :return:\n\n\n\ncore.annotation.RDFAnnotation.from_tuple(t)\nConstruct from tuple.\n\n\n\ncore.annotation.RDFAnnotation.shorten_compact_term(term, collection)\nShorten the compact terms and return term.\nIf the namespace is not embedded in the term return the shortened term.\n\n\n\ncore.annotation.RDFAnnotation.to_dict()\nConvert to dict.\n\n\n\ncore.annotation.RDFAnnotation.validate()\nValidate annotation.\n\n\n\n\n\ncore.annotation.RDFAnnotationData(annotation)\nAnnotation with resolved information.\nqueries for the resource should happen here; this resolves additional information.\n\n\n\n\n\nName\nDescription\n\n\n\n\nquery_ols\nQuery ontology lookup service.\n\n\nto_dict\nConvert to dict.\n\n\n\n\n\ncore.annotation.RDFAnnotationData.query_ols()\nQuery ontology lookup service.\n\n\n\ncore.annotation.RDFAnnotationData.to_dict()\nConvert to dict.",
    "crumbs": [
      "API Reference",
      "Annotations"
    ]
  },
  {
    "objectID": "api/omex.html",
    "href": "api/omex.html",
    "title": "omex",
    "section": "",
    "text": "omex\nCOMBINE Archive support.\nThis module provides an abstraction around the COMBINE archive. Common operations such as archive creation, archive extraction, creating archives from entries or directories, working with the manifest.xml are implemented.\nWhen working with COMBINE archives these wrapper functions should be used. The current version has no support for metadata manipulation.\nEncrypted archives can be opened, but no support for encrypting archives yet.\n\n\n\n\n\nName\nDescription\n\n\n\n\nEntryFormat\nEnum for common formats.\n\n\nManifest\nCOMBINE archive manifest.\n\n\nManifestEntry\nEntry of an OMEX file listed in the manifest.xml.\n\n\nOmex\nCombine archive class.\n\n\n\n\n\nomex.EntryFormat()\nEnum for common formats.\n\n\n\nomex.Manifest(**data)\nCOMBINE archive manifest.\nA manifest is a list of ManifestEntries.\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_entry\nAdd entry to manifest.\n\n\nfrom_manifest\nCreate manifest from existing manifest.xml file.\n\n\nremove_entry_for_location\nRemove entry for given location.\n\n\nto_manifest\nWrite manifest.xml.\n\n\nto_manifest_xml\nCreate xml of manifest.\n\n\n\n\n\nomex.Manifest.add_entry(entry)\nAdd entry to manifest.\nDoes not check for duplication.\n\n\n\nomex.Manifest.from_manifest(manifest_path)\nCreate manifest from existing manifest.xml file.\n\n\n\nomex.Manifest.remove_entry_for_location(location)\nRemove entry for given location.\n\n\n\nomex.Manifest.to_manifest(manifest_path)\nWrite manifest.xml.\n\n\n\nomex.Manifest.to_manifest_xml()\nCreate xml of manifest.\n\n\n\n\n\nomex.ManifestEntry()\nEntry of an OMEX file listed in the manifest.xml.\nThis corresponds to a single file in the archive which is tracked in the manifest.xml. location: location of the entry format: full format string master: master attribute\n\n\n\n\n\nName\nDescription\n\n\n\n\nis_format\nCheck if entry is of the given format_key.\n\n\nis_sbgn\nCheck if entry is SBGN.\n\n\nis_sbml\nCheck if entry is SBML.\n\n\nis_sedml\nCheck if entry is SED-ML.\n\n\n\n\n\nomex.ManifestEntry.is_format(format_key, format)\nCheck if entry is of the given format_key.\n\n\n\nomex.ManifestEntry.is_sbgn()\nCheck if entry is SBGN.\n\n\n\nomex.ManifestEntry.is_sbml()\nCheck if entry is SBML.\n\n\n\nomex.ManifestEntry.is_sedml()\nCheck if entry is SED-ML.\n\n\n\n\n\nomex.Omex()\nCombine archive class.\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_entry\nAdd a path to the combine archive.\n\n\nentries_by_format\nGet entries with given format in the archive.\n\n\nfrom_directory\nCreate a COMBINE archive from a given directory.\n\n\nfrom_omex\nRead omex from given path.\n\n\nget_path\nGet path for given location.\n\n\nguess_format\nGuess format string for given file.\n\n\nis_omex\nCheck if path is an omex archive.\n\n\nlookup_format\nLookup format by format_key.\n\n\nremove_entry_for_location\nRemove entry and corresponding entry_path.\n\n\nto_directory\nExtract combine archive to output directory.\n\n\nto_omex\nWrite omex to path.\n\n\n\n\n\nomex.Omex.add_entry(entry_path, entry)\nAdd a path to the combine archive.\nThe corresponding ManifestEntry information is required. The entry is copied when getting added, i.e., changes to the location after adding an entry will not have any effect on the content in the archive!\n\n\n\nomex.Omex.entries_by_format(format_key)\nGet entries with given format in the archive.\n\n\n\nomex.Omex.from_directory(directory)\nCreate a COMBINE archive from a given directory.\nThe file types are inferred, in case of existing manifest or metadata information this should be reused.\nFor all SED-ML files in the directory the master attribute is set to True.\n\n\n\nomex.Omex.from_omex(omex_path, password=None)\nRead omex from given path.\n:param omex_path: path to omex archive :param password: password for encryption :return: Omex object\n\n\n\nomex.Omex.get_path(location)\nGet path for given location.\n\n\n\nomex.Omex.guess_format(path)\nGuess format string for given file.\nIf string cannot be resolved ’’ is returned.\n\n\n\nomex.Omex.is_omex(omex_path)\nCheck if path is an omex archive.\nFile must be a zip archive and contain a manifest.xml.\n\n\n\nomex.Omex.lookup_format(format_key)\nLookup format by format_key.\n\n\n\nomex.Omex.remove_entry_for_location(location)\nRemove entry and corresponding entry_path.\n\n\n\nomex.Omex.to_directory(output_dir)\nExtract combine archive to output directory.\n:param output_dir: output directory :return:\n\n\n\nomex.Omex.to_omex(\n    omex_path,\n    password=None,\n    compression=zipfile.ZIP_DEFLATED,\n    compresslevel=9,\n)\nWrite omex to path.\nBy definition OMEX files should be zip deflated.\nThe compresslevel parameter controls the compression level to use when writing files to the archive. When using ZIP_STORED or ZIP_LZMA it has no effect. When using ZIP_DEFLATED integers 0 through 9 are accepted (see zlib for more information). When using ZIP_BZIP2 integers 1 through 9 are accepted (see bz2 for more information). The larger the value the better te compression\n:param omex_path: :param compression: compression algorithm :param compresslevel: level of compression :return:",
    "crumbs": [
      "API Reference",
      "COMBINE archive"
    ]
  },
  {
    "objectID": "api/omex.html#classes",
    "href": "api/omex.html#classes",
    "title": "omex",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nEntryFormat\nEnum for common formats.\n\n\nManifest\nCOMBINE archive manifest.\n\n\nManifestEntry\nEntry of an OMEX file listed in the manifest.xml.\n\n\nOmex\nCombine archive class.\n\n\n\n\n\nomex.EntryFormat()\nEnum for common formats.\n\n\n\nomex.Manifest(**data)\nCOMBINE archive manifest.\nA manifest is a list of ManifestEntries.\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_entry\nAdd entry to manifest.\n\n\nfrom_manifest\nCreate manifest from existing manifest.xml file.\n\n\nremove_entry_for_location\nRemove entry for given location.\n\n\nto_manifest\nWrite manifest.xml.\n\n\nto_manifest_xml\nCreate xml of manifest.\n\n\n\n\n\nomex.Manifest.add_entry(entry)\nAdd entry to manifest.\nDoes not check for duplication.\n\n\n\nomex.Manifest.from_manifest(manifest_path)\nCreate manifest from existing manifest.xml file.\n\n\n\nomex.Manifest.remove_entry_for_location(location)\nRemove entry for given location.\n\n\n\nomex.Manifest.to_manifest(manifest_path)\nWrite manifest.xml.\n\n\n\nomex.Manifest.to_manifest_xml()\nCreate xml of manifest.\n\n\n\n\n\nomex.ManifestEntry()\nEntry of an OMEX file listed in the manifest.xml.\nThis corresponds to a single file in the archive which is tracked in the manifest.xml. location: location of the entry format: full format string master: master attribute\n\n\n\n\n\nName\nDescription\n\n\n\n\nis_format\nCheck if entry is of the given format_key.\n\n\nis_sbgn\nCheck if entry is SBGN.\n\n\nis_sbml\nCheck if entry is SBML.\n\n\nis_sedml\nCheck if entry is SED-ML.\n\n\n\n\n\nomex.ManifestEntry.is_format(format_key, format)\nCheck if entry is of the given format_key.\n\n\n\nomex.ManifestEntry.is_sbgn()\nCheck if entry is SBGN.\n\n\n\nomex.ManifestEntry.is_sbml()\nCheck if entry is SBML.\n\n\n\nomex.ManifestEntry.is_sedml()\nCheck if entry is SED-ML.\n\n\n\n\n\nomex.Omex()\nCombine archive class.\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_entry\nAdd a path to the combine archive.\n\n\nentries_by_format\nGet entries with given format in the archive.\n\n\nfrom_directory\nCreate a COMBINE archive from a given directory.\n\n\nfrom_omex\nRead omex from given path.\n\n\nget_path\nGet path for given location.\n\n\nguess_format\nGuess format string for given file.\n\n\nis_omex\nCheck if path is an omex archive.\n\n\nlookup_format\nLookup format by format_key.\n\n\nremove_entry_for_location\nRemove entry and corresponding entry_path.\n\n\nto_directory\nExtract combine archive to output directory.\n\n\nto_omex\nWrite omex to path.\n\n\n\n\n\nomex.Omex.add_entry(entry_path, entry)\nAdd a path to the combine archive.\nThe corresponding ManifestEntry information is required. The entry is copied when getting added, i.e., changes to the location after adding an entry will not have any effect on the content in the archive!\n\n\n\nomex.Omex.entries_by_format(format_key)\nGet entries with given format in the archive.\n\n\n\nomex.Omex.from_directory(directory)\nCreate a COMBINE archive from a given directory.\nThe file types are inferred, in case of existing manifest or metadata information this should be reused.\nFor all SED-ML files in the directory the master attribute is set to True.\n\n\n\nomex.Omex.from_omex(omex_path, password=None)\nRead omex from given path.\n:param omex_path: path to omex archive :param password: password for encryption :return: Omex object\n\n\n\nomex.Omex.get_path(location)\nGet path for given location.\n\n\n\nomex.Omex.guess_format(path)\nGuess format string for given file.\nIf string cannot be resolved ’’ is returned.\n\n\n\nomex.Omex.is_omex(omex_path)\nCheck if path is an omex archive.\nFile must be a zip archive and contain a manifest.xml.\n\n\n\nomex.Omex.lookup_format(format_key)\nLookup format by format_key.\n\n\n\nomex.Omex.remove_entry_for_location(location)\nRemove entry and corresponding entry_path.\n\n\n\nomex.Omex.to_directory(output_dir)\nExtract combine archive to output directory.\n:param output_dir: output directory :return:\n\n\n\nomex.Omex.to_omex(\n    omex_path,\n    password=None,\n    compression=zipfile.ZIP_DEFLATED,\n    compresslevel=9,\n)\nWrite omex to path.\nBy definition OMEX files should be zip deflated.\nThe compresslevel parameter controls the compression level to use when writing files to the archive. When using ZIP_STORED or ZIP_LZMA it has no effect. When using ZIP_DEFLATED integers 0 through 9 are accepted (see zlib for more information). When using ZIP_BZIP2 integers 1 through 9 are accepted (see bz2 for more information). The larger the value the better te compression\n:param omex_path: :param compression: compression algorithm :param compresslevel: level of compression :return:",
    "crumbs": [
      "API Reference",
      "COMBINE archive"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pymetadata: python utilities for metadata and COMBINE archives",
    "section": "",
    "text": "pymetadata: python utilities for metadata and COMBINE archives\n    \npymetadata is a collection of python utilities for working with metadata in the context of COMBINE standards with source code available from https://github.com/matthiaskoenig/pymetadata.\nFeatures include among others\n\nCOMBINE archive version 1 support (OMEX)\nannotation classes and helpers\nSBO, KISAO and ECO ontology enums\n\nIf you have any questions or issues please open an issue.\nDocumentation is available from https://matthiaskoenig.github.io/pymetadata.\n\n\nHow to cite\n\n\n\nLicense\n\nSource Code: MIT\nDocumentation: CC BY-SA 4.0\n\n\n\nFunding\nMatthias König is supported and by the German Research Foundation (DFG) within the Research Unit Programme FOR 5151 “QuaLiPerF (Quantifying Liver Perfusion-Function Relationship in Complex Resection - A Systems Medicine Approach)” by grant number 436883643 and by grant number 465194077 (Priority Programme SPP 2311, Subproject SimLivA).\nMatthias König was supported by the Federal Ministry of Education and Research (BMBF, Germany) within the research network Systems Medicine of the Liver (LiSyM, grant number 031L0054).\n© 2021-2026 Matthias König",
    "crumbs": [
      "pymetadata: python utilities for metadata and COMBINE archives"
    ]
  }
]
