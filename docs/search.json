[
  {
    "objectID": "presentations/HARMONY2026/pymetadata.html#combine-archive-omex",
    "href": "presentations/HARMONY2026/pymetadata.html#combine-archive-omex",
    "title": "pymetadata",
    "section": "COMBINE archive (OMEX)1 ",
    "text": "COMBINE archive (OMEX)1 \n\n\n\n*.omex: Consists of a single ZIP-based file (with .omex extension) that bundles models, simulation descriptions, data files, and metadata needed to fully reproduce a study.\nManifest: Uses a manifest.xml file to catalog contents, including file locations and formats like SBML\nSharing: Enables sharing complete, reproducible simulation studies rather than scattered files.\n\n\n\n\nBergmann et al. (2014), Bergmann, Rodriguez, and Le Novère (2015)"
  },
  {
    "objectID": "presentations/HARMONY2026/pymetadata.html#omex-metadata",
    "href": "presentations/HARMONY2026/pymetadata.html#omex-metadata",
    "title": "pymetadata",
    "section": "OMEX Metadata",
    "text": "OMEX Metadata\n\n\n\nFAIR_ Metadata is crucial for FAIR1 modelling workflows (findable, interoperable)\nHarmonization: Important to harmonize semantic annotations efforts across standards and modeling domains2\nDescription of models, model components and workflows (e.g. canagliflozin-model3) \n\n\n\n\nWilkinson et al. (2016)Neal et al. (2019)Tereshchuk, Elias, and König (2026b), Tereshchuk, Elias, and König (2026a)"
  },
  {
    "objectID": "presentations/HARMONY2026/pymetadata.html#pymetadata",
    "href": "presentations/HARMONY2026/pymetadata.html#pymetadata",
    "title": "pymetadata",
    "section": "pymetadata1",
    "text": "pymetadata1\n\n\n\nSupports reading, writing and display of COMBINE archive (OMEX)2\nValidation of metadata against identifiers.org3 and MIRIAM4 registry\nNormalization of metadata\nResolving metadata via ontology lookup service (OLS4)5\nnew: py3.10 - py3.14 support\nnew: documentation: https://matthiaskoenig.github.io/pymetadata/\n\n\n\n\nKönig (2026)Bergmann et al. (2014), Bergmann, Rodriguez, and Le Novère (2015)Bernal-Llinares et al. (2021)Laibe and Le Novère (2007)McLaughlin2025"
  },
  {
    "objectID": "presentations/HARMONY2026/pymetadata.html#create-combine-archive",
    "href": "presentations/HARMONY2026/pymetadata.html#create-combine-archive",
    "title": "pymetadata",
    "section": "1. Create COMBINE archive",
    "text": "1. Create COMBINE archive\n\n# Create archive from file\nomex = Omex()\nomex.add_entry(\n    entry_path=Path(\"results/testomex/models/omex_comp_flat.xml\"),\n    entry=ManifestEntry(location=\"./model.xml\",\n    format=EntryFormat.SBML, master=False),\n)\nomex.add_entry(\n    entry_path=Path(\"results/testomex/README.md\"),\n    entry=ManifestEntry(\n        location=\"./README.md\", format=EntryFormat.MARKDOWN, master=False\n    ),\n)\nomex.to_omex(Path(\"results/test_from_files.omex\"))\nconsole.print(omex)"
  },
  {
    "objectID": "presentations/HARMONY2026/pymetadata.html#load-from-url",
    "href": "presentations/HARMONY2026/pymetadata.html#load-from-url",
    "title": "pymetadata",
    "section": "2. Load from URL",
    "text": "2. Load from URL\nfrom pymetadata.console import console\nfrom pymetadata.omex import Omex\n\nomex_url = \"https://github.com/matthiaskoenig/canagliflozin-model/releases/download/0.7.0/canagliflozin_model.omex\"\nomex = Omex.from_url(omex_url)\nconsole.print(omex)\n[\n  ManifestEntry(location='.', format='http://identifiers.org/combine.specifications/omex', master=False),\n  ManifestEntry(location='./manifest.xml', format='http://identifiers.org/combine.specifications/omex-manifest', master=False),\n  ManifestEntry(location='./README.md', format='https://purl.org/NET/mediatypes/text/x-markdown', master=False),\n  ManifestEntry(location='./cc-by-sa-4.0.txt', format='https://purl.org/NET/mediatypes/text/plain', master=False),\n  ManifestEntry(location='./mit.txt', format='https://purl.org/NET/mediatypes/text/plain', master=False),\n  ManifestEntry(location='./models/canagliflozin_intestine.xml', format='http://identifiers.org/combine.specifications/sbml.level-3.version-2', master=False),\n  ...\n  ManifestEntry(location='./figures/canagliflozin_model.png', format='https://purl.org/NET/mediatypes/image/png', master=False)\n]"
  },
  {
    "objectID": "presentations/HARMONY2026/pymetadata.html#working-with-sbo",
    "href": "presentations/HARMONY2026/pymetadata.html#working-with-sbo",
    "title": "pymetadata",
    "section": "3. Working with SBO",
    "text": "3. Working with SBO\n# using SBO terms\nfrom pymetadata.console import console\nfrom pymetadata.metadata import SBO\n\nsbo_term1 = SBO.SIMPLE_CHEMICAL\nsbo_term2 = SBO.PROCESS\n\nfor sbo in [sbo_term1, sbo_term2]:\n    console.print(sbo)\nSBO_0000247\nSBO_0000375\n\nenums for simple access to SBO"
  },
  {
    "objectID": "presentations/HARMONY2026/pymetadata.html#harmonizing-annotations",
    "href": "presentations/HARMONY2026/pymetadata.html#harmonizing-annotations",
    "title": "pymetadata",
    "section": "4. Harmonizing annotations",
    "text": "4. Harmonizing annotations\nfrom pymetadata.console import console\nfrom pymetadata.identifiers.miriam import BQB, BQM\nfrom pymetadata.core.annotation import RDFAnnotation\n\nfor resource in [\n    \"urn:miriam:chebi:CHEBI%3A33699\",\n    \"CHEBI:33699\",\n    \"chebi/CHEBI:33699\",\n    \"https://identifiers.org/chebi/CHEBI:33699\",\n    \"http://identifiers.org/CHEBI:33699\",\n]:\n    a = RDFAnnotation(qualifier=BQB.IS, resource=resource)\n    console.print(a)\nRDFAnnotation(BQB.IS|chebi|CHEBI:33699|identifiers.org)\nRDFAnnotation(BQB.IS|chebi|CHEBI:33699|identifiers.org)\nRDFAnnotation(BQB.IS|chebi|CHEBI:33699|identifiers.org)\nRDFAnnotation(BQB.IS|chebi|CHEBI:33699|identifiers.org)\nRDFAnnotation(BQB.IS|chebi|CHEBI:33699|identifiers.org)\n\nnormalizing multitude of patterns found in models and resources"
  },
  {
    "objectID": "presentations/HARMONY2026/pymetadata.html#validating-annotations",
    "href": "presentations/HARMONY2026/pymetadata.html#validating-annotations",
    "title": "pymetadata",
    "section": "5. Validating annotations",
    "text": "5. Validating annotations\nfrom pymetadata.console import console\nfrom pymetadata.identifiers.miriam import BQB, BQM\nfrom pymetadata.core.annotation import RDFAnnotation\n\nfor resource in [\n    \"CHEB:33699\",\n    \"chebi/CHEBI:X33699\",\n]:\n    a = RDFAnnotation(qualifier=BQB.IS, resource=resource)\n    console.print(a)\nERROR    MIRIAM namespace `cheb` does not exist for `RDFAnnotation(BQB.IS|cheb|CHEB:33699|identifiers.org)`\nRDFAnnotation(BQB.IS|cheb|CHEB:33699|identifiers.org)\n\nERROR    Term `CHEBI:X33699` did not match pattern `^CHEBI:\\d+$` for collection `chebi`.\nRDFAnnotation(BQB.IS|chebi|CHEBI:X33699|identifiers.org)\n\nvalidation of namespaces and patterns"
  },
  {
    "objectID": "presentations/HARMONY2026/pymetadata.html#want-to-know-more",
    "href": "presentations/HARMONY2026/pymetadata.html#want-to-know-more",
    "title": "pymetadata",
    "section": "Want to know more",
    "text": "Want to know more\n\n\n\n\n\n\n\n\n\n\n\npymetadata documentation\n\n\n\n\nBergmann, Frank T., Richard Adams, Stuart Moodie, Jonathan Cooper, Mihai Glont, Martin Golebiewski, Michael Hucka, et al. 2014. “COMBINE Archive and OMEX Format: One File to Share All Information to Reproduce a Modeling Project.” BMC Bioinformatics 15 (1): 369. https://doi.org/10.1186/s12859-014-0369-z.\n\n\nBergmann, Frank T., Nicolas Rodriguez, and Nicolas Le Novère. 2015. “COMBINE Archive Specification Version 1.” Journal of Integrative Bioinformatics 12 (2): 261. https://doi.org/10.2390/biecoll-jib-2015-261.\n\n\nBernal-Llinares, Manuel, Javier Ferrer-Gómez, Nick Juty, Carole Goble, Sarala M. Wimalaratne, and Henning Hermjakob. 2021. “Identifiers.org: Compact Identifier Services in the Cloud.” Bioinformatics 37 (12): 1781–82. https://doi.org/10.1093/bioinformatics/btaa864.\n\n\nKönig, Matthias. 2026. “Pymetadata Are Python Utilities for Working with Metadata.” Zenodo. https://doi.org/10.5281/zenodo.18207746.\n\n\nLaibe, Camille, and Nicolas Le Novère. 2007. “MIRIAM Resources: Tools to Generate and Resolve Robust Cross-References in Systems Biology.” BMC Systems Biology 1 (December): 58. https://doi.org/10.1186/1752-0509-1-58.\n\n\nNeal, Maxwell Lewis, Matthias König, David Nickerson, Göksel Mısırlı, Reza Kalbasi, Andreas Dräger, Koray Atalag, et al. 2019. “Harmonizing Semantic Annotations for Computational Models in Biology.” Briefings in Bioinformatics 20 (2): 540–50. https://doi.org/10.1093/bib/bby087.\n\n\nTereshchuk, Vera, Michelle Elias, and Matthias König. 2026a. “A Digital Twin of Canagliflozin Pharmacokinetics and Pharmacodynamics in Type 2 Diabetes Mellitus.” Medicine and Pharmacology. https://doi.org/10.20944/preprints202601.2095.v1.\n\n\n———. 2026b. “Physiologically Based Pharmacokinetic/ Pharmacodynamic (PBPK/PD) Model of Canagliflozin.” Zenodo. https://doi.org/10.5281/ZENODO.13759839.\n\n\nWilkinson, Mark D., Michel Dumontier, I. Jsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. 2016. “The FAIR Guiding Principles for Scientific Data Management and Stewardship.” Scientific Data 3 (March): 160018. https://doi.org/10.1038/sdata.2016.18."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pymetadata: python utilities for metadata and COMBINE archives",
    "section": "",
    "text": "pymetadata: python utilities for metadata and COMBINE archives\n    \npymetadata is a collection of python utilities for working with metadata in the context of COMBINE standards with source code available from https://github.com/matthiaskoenig/pymetadata.\nFeatures include among others\n\nCOMBINE archive version 1 support (OMEX)\nannotation classes and helpers\nSBO, KISAO and ECO ontology enums\n\nIf you have any questions or issues please open an issue.\nDocumentation is available from https://matthiaskoenig.github.io/pymetadata.\n\n\nHow to cite\n\n\n\nLicense\n\nSource Code: MIT\nDocumentation: CC BY-SA 4.0\n\n\n\nFunding\nMatthias König is supported and by the German Research Foundation (DFG) within the Research Unit Programme FOR 5151 “QuaLiPerF (Quantifying Liver Perfusion-Function Relationship in Complex Resection - A Systems Medicine Approach)” by grant number 436883643 and by grant number 465194077 (Priority Programme SPP 2311, Subproject SimLivA).\nMatthias König was supported by the Federal Ministry of Education and Research (BMBF, Germany) within the research network Systems Medicine of the Liver (LiSyM, grant number 031L0054).\n© 2021-2026 Matthias König",
    "crumbs": [
      "pymetadata: python utilities for metadata and COMBINE archives"
    ]
  },
  {
    "objectID": "api/omex.html",
    "href": "api/omex.html",
    "title": "omex",
    "section": "",
    "text": "omex\nCOMBINE Archive support.\nThis module provides an abstraction around the COMBINE archive. Common operations such as archive creation, archive extraction, creating archives from entries or directories, working with the manifest.xml are implemented.\nWhen working with COMBINE archives these wrapper functions should be used. The current version has no support for metadata manipulation.\nEncrypted archives can be opened, but no support for encrypting archives yet.\n\n\n\n\n\nName\nDescription\n\n\n\n\nEntryFormat\nEnum for common formats.\n\n\nManifest\nCOMBINE archive manifest.\n\n\nManifestEntry\nEntry of an OMEX file listed in the manifest.xml.\n\n\nOmex\nCombine archive class.\n\n\n\n\n\nomex.EntryFormat()\nEnum for common formats.\n\n\n\nomex.Manifest(**data)\nCOMBINE archive manifest.\nA manifest is a list of ManifestEntries.\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_entry\nAdd entry to manifest.\n\n\nfrom_manifest\nCreate manifest from existing manifest.xml file.\n\n\nremove_entry_for_location\nRemove entry for given location.\n\n\nto_manifest\nWrite manifest.xml.\n\n\nto_manifest_xml\nCreate xml of manifest.\n\n\n\n\n\nomex.Manifest.add_entry(entry)\nAdd entry to manifest.\nDoes not check for duplication.\n\n\n\nomex.Manifest.from_manifest(manifest_path)\nCreate manifest from existing manifest.xml file.\n\n\n\nomex.Manifest.remove_entry_for_location(location)\nRemove entry for given location.\n\n\n\nomex.Manifest.to_manifest(manifest_path)\nWrite manifest.xml.\n\n\n\nomex.Manifest.to_manifest_xml()\nCreate xml of manifest.\n\n\n\n\n\nomex.ManifestEntry()\nEntry of an OMEX file listed in the manifest.xml.\nThis corresponds to a single file in the archive which is tracked in the manifest.xml. location: location of the entry format: full format string master: master attribute\n\n\n\n\n\nName\nDescription\n\n\n\n\nis_format\nCheck if entry is of the given format_key.\n\n\nis_sbgn\nCheck if entry is SBGN.\n\n\nis_sbml\nCheck if entry is SBML.\n\n\nis_sedml\nCheck if entry is SED-ML.\n\n\n\n\n\nomex.ManifestEntry.is_format(format_key, format)\nCheck if entry is of the given format_key.\n\n\n\nomex.ManifestEntry.is_sbgn()\nCheck if entry is SBGN.\n\n\n\nomex.ManifestEntry.is_sbml()\nCheck if entry is SBML.\n\n\n\nomex.ManifestEntry.is_sedml()\nCheck if entry is SED-ML.\n\n\n\n\n\nomex.Omex()\nCombine archive class.\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_entry\nAdd a path to the combine archive.\n\n\nentries_by_format\nGet entries with given format in the archive.\n\n\nfrom_directory\nCreate a COMBINE archive from a given directory.\n\n\nfrom_omex\nRead omex from path.\n\n\nfrom_url\nRead omex from url.\n\n\nget_path\nGet path for given location.\n\n\nguess_format\nGuess format string for given file.\n\n\nis_omex\nCheck if path is an omex archive.\n\n\nlookup_format\nLookup format by format_key.\n\n\nremove_entry_for_location\nRemove entry and corresponding entry_path.\n\n\nto_directory\nExtract combine archive to output directory.\n\n\nto_omex\nWrite omex to path.\n\n\n\n\n\nomex.Omex.add_entry(entry_path, entry)\nAdd a path to the combine archive.\nThe corresponding ManifestEntry information is required. The entry is copied when getting added, i.e., changes to the location after adding an entry will not have any effect on the content in the archive!\n\n\n\nomex.Omex.entries_by_format(format_key)\nGet entries with given format in the archive.\n\n\n\nomex.Omex.from_directory(directory)\nCreate a COMBINE archive from a given directory.\nThe file types are inferred, in case of existing manifest or metadata information this should be reused.\nFor all SED-ML files in the directory the master attribute is set to True.\n\n\n\nomex.Omex.from_omex(omex_path, password=None)\nRead omex from path.\n:param omex_path: path to omex archive :param password: password for encryption :return: Omex object\n\n\n\nomex.Omex.from_url(omex_url, password=None)\nRead omex from url.\n:param url: url to omex archive :param password: password for encryption :return: Omex object\n\n\n\nomex.Omex.get_path(location)\nGet path for given location.\n\n\n\nomex.Omex.guess_format(path)\nGuess format string for given file.\nIf string cannot be resolved ’’ is returned.\n\n\n\nomex.Omex.is_omex(omex_path)\nCheck if path is an omex archive.\nFile must be a zip archive and contain a manifest.xml.\n\n\n\nomex.Omex.lookup_format(format_key)\nLookup format by format_key.\n\n\n\nomex.Omex.remove_entry_for_location(location)\nRemove entry and corresponding entry_path.\n\n\n\nomex.Omex.to_directory(output_dir)\nExtract combine archive to output directory.\n:param output_dir: output directory :return:\n\n\n\nomex.Omex.to_omex(\n    omex_path,\n    password=None,\n    compression=zipfile.ZIP_DEFLATED,\n    compresslevel=9,\n)\nWrite omex to path.\nBy definition OMEX files should be zip deflated.\nThe compresslevel parameter controls the compression level to use when writing files to the archive. When using ZIP_STORED or ZIP_LZMA it has no effect. When using ZIP_DEFLATED integers 0 through 9 are accepted (see zlib for more information). When using ZIP_BZIP2 integers 1 through 9 are accepted (see bz2 for more information). The larger the value the better te compression\n:param omex_path: :param compression: compression algorithm :param compresslevel: level of compression :return:",
    "crumbs": [
      "API Reference",
      "COMBINE archive"
    ]
  },
  {
    "objectID": "api/omex.html#classes",
    "href": "api/omex.html#classes",
    "title": "omex",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nEntryFormat\nEnum for common formats.\n\n\nManifest\nCOMBINE archive manifest.\n\n\nManifestEntry\nEntry of an OMEX file listed in the manifest.xml.\n\n\nOmex\nCombine archive class.\n\n\n\n\n\nomex.EntryFormat()\nEnum for common formats.\n\n\n\nomex.Manifest(**data)\nCOMBINE archive manifest.\nA manifest is a list of ManifestEntries.\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_entry\nAdd entry to manifest.\n\n\nfrom_manifest\nCreate manifest from existing manifest.xml file.\n\n\nremove_entry_for_location\nRemove entry for given location.\n\n\nto_manifest\nWrite manifest.xml.\n\n\nto_manifest_xml\nCreate xml of manifest.\n\n\n\n\n\nomex.Manifest.add_entry(entry)\nAdd entry to manifest.\nDoes not check for duplication.\n\n\n\nomex.Manifest.from_manifest(manifest_path)\nCreate manifest from existing manifest.xml file.\n\n\n\nomex.Manifest.remove_entry_for_location(location)\nRemove entry for given location.\n\n\n\nomex.Manifest.to_manifest(manifest_path)\nWrite manifest.xml.\n\n\n\nomex.Manifest.to_manifest_xml()\nCreate xml of manifest.\n\n\n\n\n\nomex.ManifestEntry()\nEntry of an OMEX file listed in the manifest.xml.\nThis corresponds to a single file in the archive which is tracked in the manifest.xml. location: location of the entry format: full format string master: master attribute\n\n\n\n\n\nName\nDescription\n\n\n\n\nis_format\nCheck if entry is of the given format_key.\n\n\nis_sbgn\nCheck if entry is SBGN.\n\n\nis_sbml\nCheck if entry is SBML.\n\n\nis_sedml\nCheck if entry is SED-ML.\n\n\n\n\n\nomex.ManifestEntry.is_format(format_key, format)\nCheck if entry is of the given format_key.\n\n\n\nomex.ManifestEntry.is_sbgn()\nCheck if entry is SBGN.\n\n\n\nomex.ManifestEntry.is_sbml()\nCheck if entry is SBML.\n\n\n\nomex.ManifestEntry.is_sedml()\nCheck if entry is SED-ML.\n\n\n\n\n\nomex.Omex()\nCombine archive class.\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_entry\nAdd a path to the combine archive.\n\n\nentries_by_format\nGet entries with given format in the archive.\n\n\nfrom_directory\nCreate a COMBINE archive from a given directory.\n\n\nfrom_omex\nRead omex from path.\n\n\nfrom_url\nRead omex from url.\n\n\nget_path\nGet path for given location.\n\n\nguess_format\nGuess format string for given file.\n\n\nis_omex\nCheck if path is an omex archive.\n\n\nlookup_format\nLookup format by format_key.\n\n\nremove_entry_for_location\nRemove entry and corresponding entry_path.\n\n\nto_directory\nExtract combine archive to output directory.\n\n\nto_omex\nWrite omex to path.\n\n\n\n\n\nomex.Omex.add_entry(entry_path, entry)\nAdd a path to the combine archive.\nThe corresponding ManifestEntry information is required. The entry is copied when getting added, i.e., changes to the location after adding an entry will not have any effect on the content in the archive!\n\n\n\nomex.Omex.entries_by_format(format_key)\nGet entries with given format in the archive.\n\n\n\nomex.Omex.from_directory(directory)\nCreate a COMBINE archive from a given directory.\nThe file types are inferred, in case of existing manifest or metadata information this should be reused.\nFor all SED-ML files in the directory the master attribute is set to True.\n\n\n\nomex.Omex.from_omex(omex_path, password=None)\nRead omex from path.\n:param omex_path: path to omex archive :param password: password for encryption :return: Omex object\n\n\n\nomex.Omex.from_url(omex_url, password=None)\nRead omex from url.\n:param url: url to omex archive :param password: password for encryption :return: Omex object\n\n\n\nomex.Omex.get_path(location)\nGet path for given location.\n\n\n\nomex.Omex.guess_format(path)\nGuess format string for given file.\nIf string cannot be resolved ’’ is returned.\n\n\n\nomex.Omex.is_omex(omex_path)\nCheck if path is an omex archive.\nFile must be a zip archive and contain a manifest.xml.\n\n\n\nomex.Omex.lookup_format(format_key)\nLookup format by format_key.\n\n\n\nomex.Omex.remove_entry_for_location(location)\nRemove entry and corresponding entry_path.\n\n\n\nomex.Omex.to_directory(output_dir)\nExtract combine archive to output directory.\n:param output_dir: output directory :return:\n\n\n\nomex.Omex.to_omex(\n    omex_path,\n    password=None,\n    compression=zipfile.ZIP_DEFLATED,\n    compresslevel=9,\n)\nWrite omex to path.\nBy definition OMEX files should be zip deflated.\nThe compresslevel parameter controls the compression level to use when writing files to the archive. When using ZIP_STORED or ZIP_LZMA it has no effect. When using ZIP_DEFLATED integers 0 through 9 are accepted (see zlib for more information). When using ZIP_BZIP2 integers 1 through 9 are accepted (see bz2 for more information). The larger the value the better te compression\n:param omex_path: :param compression: compression algorithm :param compresslevel: level of compression :return:",
    "crumbs": [
      "API Reference",
      "COMBINE archive"
    ]
  },
  {
    "objectID": "api/core.annotation.html",
    "href": "api/core.annotation.html",
    "title": "core.annotation",
    "section": "",
    "text": "core.annotation\nAnnotation.\nCore data structure to store annotations.\n\n\n\n\n\nName\nDescription\n\n\n\n\nProviderType\nProvider type.\n\n\nRDFAnnotation\nRDFAnnotation class.\n\n\nRDFAnnotationData\nAnnotation with resolved information.\n\n\n\n\n\ncore.annotation.ProviderType()\nProvider type.\n\n\n\ncore.annotation.RDFAnnotation(qualifier, resource, validate=True)\nRDFAnnotation class.\nBasic storage of annotation information. This consists of the relation and the resource. The annotations can be attached to other objects thereby forming triples which can be converted to RDF.\n\n\n\nhttp(s)://identifiers.org/collection/term, i.e., a identifiers.org URI\ncollection/term, i.e., the combination of collection and term\nhttp(s)://arbitrary.url, an arbitrary URL\nurn:miriam:uniprot:P03023\nhttps://bioregistry.io/chebi:15996 urls via the bioregistry provider\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nresource_normalized\nNormalize resource for given annotation.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncheck_miriam_term\nCheck that term follows id pattern for collection.\n\n\ncheck_qualifier\nCheck that the qualifier is an allowed qualifier.\n\n\nfrom_tuple\nConstruct from tuple.\n\n\nshorten_compact_term\nShorten the compact terms and return term.\n\n\nto_dict\nConvert to dict.\n\n\nvalidate\nValidate annotation.\n\n\n\n\n\ncore.annotation.RDFAnnotation.check_miriam_term()\nCheck that term follows id pattern for collection.\nUses the Identifiers collection information.\n\n\n\ncore.annotation.RDFAnnotation.check_qualifier(qualifier)\nCheck that the qualifier is an allowed qualifier.\n:param qualifier: :return:\n\n\n\ncore.annotation.RDFAnnotation.from_tuple(t)\nConstruct from tuple.\n\n\n\ncore.annotation.RDFAnnotation.shorten_compact_term(term, collection)\nShorten the compact terms and return term.\nIf the namespace is not embedded in the term return the shortened term.\n\n\n\ncore.annotation.RDFAnnotation.to_dict()\nConvert to dict.\n\n\n\ncore.annotation.RDFAnnotation.validate()\nValidate annotation.\n\n\n\n\n\ncore.annotation.RDFAnnotationData(annotation)\nAnnotation with resolved information.\nqueries for the resource should happen here; this resolves additional information.\n\n\n\n\n\nName\nDescription\n\n\n\n\nquery_ols\nQuery ontology lookup service.\n\n\nto_dict\nConvert to dict.\n\n\n\n\n\ncore.annotation.RDFAnnotationData.query_ols()\nQuery ontology lookup service.\n\n\n\ncore.annotation.RDFAnnotationData.to_dict()\nConvert to dict.",
    "crumbs": [
      "API Reference",
      "Annotations"
    ]
  },
  {
    "objectID": "api/core.annotation.html#classes",
    "href": "api/core.annotation.html#classes",
    "title": "core.annotation",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nProviderType\nProvider type.\n\n\nRDFAnnotation\nRDFAnnotation class.\n\n\nRDFAnnotationData\nAnnotation with resolved information.\n\n\n\n\n\ncore.annotation.ProviderType()\nProvider type.\n\n\n\ncore.annotation.RDFAnnotation(qualifier, resource, validate=True)\nRDFAnnotation class.\nBasic storage of annotation information. This consists of the relation and the resource. The annotations can be attached to other objects thereby forming triples which can be converted to RDF.\n\n\n\nhttp(s)://identifiers.org/collection/term, i.e., a identifiers.org URI\ncollection/term, i.e., the combination of collection and term\nhttp(s)://arbitrary.url, an arbitrary URL\nurn:miriam:uniprot:P03023\nhttps://bioregistry.io/chebi:15996 urls via the bioregistry provider\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nresource_normalized\nNormalize resource for given annotation.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncheck_miriam_term\nCheck that term follows id pattern for collection.\n\n\ncheck_qualifier\nCheck that the qualifier is an allowed qualifier.\n\n\nfrom_tuple\nConstruct from tuple.\n\n\nshorten_compact_term\nShorten the compact terms and return term.\n\n\nto_dict\nConvert to dict.\n\n\nvalidate\nValidate annotation.\n\n\n\n\n\ncore.annotation.RDFAnnotation.check_miriam_term()\nCheck that term follows id pattern for collection.\nUses the Identifiers collection information.\n\n\n\ncore.annotation.RDFAnnotation.check_qualifier(qualifier)\nCheck that the qualifier is an allowed qualifier.\n:param qualifier: :return:\n\n\n\ncore.annotation.RDFAnnotation.from_tuple(t)\nConstruct from tuple.\n\n\n\ncore.annotation.RDFAnnotation.shorten_compact_term(term, collection)\nShorten the compact terms and return term.\nIf the namespace is not embedded in the term return the shortened term.\n\n\n\ncore.annotation.RDFAnnotation.to_dict()\nConvert to dict.\n\n\n\ncore.annotation.RDFAnnotation.validate()\nValidate annotation.\n\n\n\n\n\ncore.annotation.RDFAnnotationData(annotation)\nAnnotation with resolved information.\nqueries for the resource should happen here; this resolves additional information.\n\n\n\n\n\nName\nDescription\n\n\n\n\nquery_ols\nQuery ontology lookup service.\n\n\nto_dict\nConvert to dict.\n\n\n\n\n\ncore.annotation.RDFAnnotationData.query_ols()\nQuery ontology lookup service.\n\n\n\ncore.annotation.RDFAnnotationData.to_dict()\nConvert to dict.",
    "crumbs": [
      "API Reference",
      "Annotations"
    ]
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "Function reference",
    "section": "",
    "text": "Functionality related to COMBINE archive (OMEX).\n\n\n\nomex\nCOMBINE Archive support.\n\n\n\n\n\n\nFunctionality related to metadata and annotations.\n\n\n\ncore.annotation\nAnnotation.",
    "crumbs": [
      "API Reference",
      "Overview"
    ]
  },
  {
    "objectID": "api/index.html#combine-archive",
    "href": "api/index.html#combine-archive",
    "title": "Function reference",
    "section": "",
    "text": "Functionality related to COMBINE archive (OMEX).\n\n\n\nomex\nCOMBINE Archive support.",
    "crumbs": [
      "API Reference",
      "Overview"
    ]
  },
  {
    "objectID": "api/index.html#metadata",
    "href": "api/index.html#metadata",
    "title": "Function reference",
    "section": "",
    "text": "Functionality related to metadata and annotations.\n\n\n\ncore.annotation\nAnnotation.",
    "crumbs": [
      "API Reference",
      "Overview"
    ]
  },
  {
    "objectID": "development.html",
    "href": "development.html",
    "title": "Development",
    "section": "",
    "text": "To set up everything for the develop environment use\n# install core dependencies\nuv sync\n\n# install dev dependencies\nuv pip install -r pyproject.toml --extra dev\nuv tool install tox --with tox-uv\n\n# setup pre-commit hook\nuv pip install pre-commit\npre-commit install\npre-commit run\n\n\n\nTesting is performed with pytest and tox:\nRun single tox target:\ntox r -e py314\nRun all tests in parallel:\ntox run-parallel",
    "crumbs": [
      "Contributing",
      "Development"
    ]
  },
  {
    "objectID": "development.html#setup-development-environment",
    "href": "development.html#setup-development-environment",
    "title": "Development",
    "section": "",
    "text": "To set up everything for the develop environment use\n# install core dependencies\nuv sync\n\n# install dev dependencies\nuv pip install -r pyproject.toml --extra dev\nuv tool install tox --with tox-uv\n\n# setup pre-commit hook\nuv pip install pre-commit\npre-commit install\npre-commit run",
    "crumbs": [
      "Contributing",
      "Development"
    ]
  },
  {
    "objectID": "development.html#testing",
    "href": "development.html#testing",
    "title": "Development",
    "section": "",
    "text": "Testing is performed with pytest and tox:\nRun single tox target:\ntox r -e py314\nRun all tests in parallel:\ntox run-parallel",
    "crumbs": [
      "Contributing",
      "Development"
    ]
  },
  {
    "objectID": "installation.html",
    "href": "installation.html",
    "title": "Installation",
    "section": "",
    "text": "pymetadata is available from pypi and can be installed via\npip install pymetadata\n\n\npymetadata caches some information for faster retrieval. The cache path is set to\nCACHE_PATH: Path = Path.home() / \".cache\" / \"pymetadata\"\nTo use a custom cache path use\nimport pymetadata\npymetadata.CACHE_PATH = &lt;cache_path&gt;",
    "crumbs": [
      "Installation"
    ]
  },
  {
    "objectID": "installation.html#cache-path",
    "href": "installation.html#cache-path",
    "title": "Installation",
    "section": "",
    "text": "pymetadata caches some information for faster retrieval. The cache path is set to\nCACHE_PATH: Path = Path.home() / \".cache\" / \"pymetadata\"\nTo use a custom cache path use\nimport pymetadata\npymetadata.CACHE_PATH = &lt;cache_path&gt;",
    "crumbs": [
      "Installation"
    ]
  }
]
